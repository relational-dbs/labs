{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a336b71a",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffd72be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSTGRESQL_START_FROM_SCRATCH = True\n",
    "DOCKER_INTERNAL_HOST = \"host.docker.internal\"\n",
    "\n",
    "POSTGRESQL_VPN_DNS = \"10.15.20.1\"\n",
    "POSTGRESQL_VPN_SELF_HOSTNAME = \"mavasbel.vpn.itam.mx\"\n",
    "POSTGRESQL_VPN_SELF_IP = \"10.15.20.2\"\n",
    "\n",
    "POSTGRESQL_BASE_PORT = 5423\n",
    "POSTGRESQL_WORKDIR = \"/var/lib/postgresql\"\n",
    "\n",
    "POSTGRESQL_INIT_USER = \"postgres\"\n",
    "POSTGRESQL_INIT_PASSWORD = \"password\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbe0ea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class DatabasesList(str, Enum):\n",
    "    BANK = \"bank_db\"\n",
    "    ECOMMERCE = \"ecommerce_db\"\n",
    "    HEALTHCARE = \"healthcare_db\"\n",
    "    SOCIAL_MEDIA = \"social_media_db\"\n",
    "    STREAMING = \"streaming_service_db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd36cfbe",
   "metadata": {},
   "source": [
    "# Schema: Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e030e527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è PostgreSQL Database wiped clean.\n",
      "‚úÖ Schema built. Ready for seeding.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import Optional, cast\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from faker import Faker\n",
    "from mimesis import Generic\n",
    "from sqlmodel import Field, SQLModel, Session, create_engine, text\n",
    "from sqlalchemy.orm import registry\n",
    "\n",
    "\n",
    "mim_generic = Generic(locale=\"en\")\n",
    "fake = Faker()\n",
    "\n",
    "db_url = f\"postgresql+psycopg2://{POSTGRESQL_INIT_USER}:{POSTGRESQL_INIT_PASSWORD}@postgres.{POSTGRESQL_VPN_SELF_HOSTNAME}:{POSTGRESQL_BASE_PORT}/{DatabasesList.BANK.value}\"\n",
    "db_engine = create_engine(db_url)\n",
    "\n",
    "with Session(db_engine) as session:\n",
    "    session.exec(text(\"DROP SCHEMA public CASCADE;\"))\n",
    "    session.exec(text(\"CREATE SCHEMA public;\"))\n",
    "    # session.exec(text(\"GRANT ALL ON SCHEMA public TO public;\"))\n",
    "    session.exec(text(f\"GRANT ALL ON SCHEMA public TO {POSTGRESQL_INIT_USER};\"))\n",
    "    session.commit()\n",
    "print(\"üóëÔ∏è PostgreSQL Database wiped clean.\")\n",
    "\n",
    "SQLModel.metadata.clear()\n",
    "if hasattr(SQLModel, \"registry\"):\n",
    "    SQLModel.registry.dispose()\n",
    "registry().dispose()\n",
    "\n",
    "# --- 1. References ---\n",
    "\n",
    "\n",
    "class Country(SQLModel, table=True):\n",
    "    id: Optional[int] = Field(default=None, primary_key=True)\n",
    "    name: str = Field(\n",
    "        default_factory=lambda: cast(Faker, fake.unique).country(), unique=True\n",
    "    )\n",
    "    code: str = Field(default_factory=lambda: cast(Faker, fake.unique).country_code())\n",
    "\n",
    "\n",
    "class City(SQLModel, table=True):\n",
    "    id: Optional[int] = Field(default=None, primary_key=True)\n",
    "    name: str = Field(default_factory=mim_generic.address.city)\n",
    "    country_id: int = Field(foreign_key=\"country.id\")\n",
    "\n",
    "\n",
    "class Currency(SQLModel, table=True):\n",
    "    id: Optional[int] = Field(default=None, primary_key=True)\n",
    "    name: str = Field(default_factory=lambda: cast(Faker, fake.unique).currency_name())\n",
    "    code: str = Field(\n",
    "        default_factory=lambda: cast(Faker, fake.unique).currency_code(), unique=True\n",
    "    )\n",
    "    symbol: str = Field(default_factory=lambda: fake.currency_symbol())\n",
    "\n",
    "\n",
    "# --- 2. Organization ---\n",
    "\n",
    "\n",
    "class Branch(SQLModel, table=True):\n",
    "    id: Optional[int] = Field(default=None, primary_key=True)\n",
    "    name: str = Field(default_factory=lambda: f\"{cast(Faker, fake.unique).company()}\")\n",
    "    address: str = Field(default_factory=mim_generic.address.address)\n",
    "    city_id: int = Field(foreign_key=\"city.id\")\n",
    "\n",
    "\n",
    "# --- 3. Customers ---\n",
    "\n",
    "\n",
    "class User(SQLModel, table=True):\n",
    "    id: Optional[int] = Field(default=None, primary_key=True)\n",
    "    username: str = Field(\n",
    "        default_factory=lambda: f\"{cast(Faker, fake.unique).user_name()}\",\n",
    "        unique=True,\n",
    "    )\n",
    "    email: str = Field(default_factory=lambda: f\"{cast(Faker, fake.unique).email()}\")\n",
    "    password: str = Field(\n",
    "        default_factory=lambda: mim_generic.person.password(\n",
    "            length=random.randint(12, 32), hashed=True\n",
    "        )\n",
    "    )\n",
    "    first_name: str = Field(default_factory=mim_generic.person.first_name)\n",
    "    last_name: str = Field(default_factory=mim_generic.person.last_name)\n",
    "    ssn: str = Field(\n",
    "        default_factory=lambda: cast(Faker, fake.unique).ssn(), unique=True\n",
    "    )\n",
    "\n",
    "\n",
    "class Account(SQLModel, table=True):\n",
    "    id: Optional[int] = Field(default=None, primary_key=True)\n",
    "    account_number: str = Field(\n",
    "        default_factory=lambda: cast(Faker, fake.unique).iban(), unique=True\n",
    "    )\n",
    "    balance: float = Field(\n",
    "        default_factory=lambda: round(random.uniform(1000.0, 10000.0), 2)\n",
    "    )\n",
    "    account_type: str = Field(\n",
    "        default_factory=lambda: fake.random_element([\"Savings\", \"Checking\"])\n",
    "    )\n",
    "    user_id: int = Field(foreign_key=\"user.id\")\n",
    "    currency_id: int = Field(foreign_key=\"currency.id\")\n",
    "    branch_id: int = Field(foreign_key=\"branch.id\")\n",
    "\n",
    "\n",
    "# --- 4. Operations ---\n",
    "\n",
    "\n",
    "class Card(SQLModel, table=True):\n",
    "    id: Optional[int] = Field(default=None, primary_key=True)\n",
    "    card_number: str = Field(\n",
    "        default_factory=lambda: cast(Faker, fake.unique).credit_card_number(),\n",
    "        unique=True,\n",
    "    )\n",
    "    card_holder_name: str = Field(\n",
    "        default=\"N/A\"\n",
    "    )  # Populated during seeding from User table\n",
    "    card_type: str = Field(\n",
    "        default_factory=lambda: fake.random_element([\"Debit\", \"Credit\"])\n",
    "    )\n",
    "    cvv: str = Field(default_factory=fake.credit_card_security_code)\n",
    "    expiry_date: str = Field(default_factory=fake.credit_card_expire)\n",
    "    account_id: int = Field(foreign_key=\"account.id\")\n",
    "\n",
    "\n",
    "class Deposit(SQLModel, table=True):\n",
    "    id: Optional[int] = Field(default=None, primary_key=True)\n",
    "    amount: float = Field(\n",
    "        default_factory=lambda: fake.pyfloat(\n",
    "            positive=True, min_value=1, max_value=10000\n",
    "        )\n",
    "    )\n",
    "    timestamp: datetime = Field(\n",
    "        default_factory=lambda: fake.date_time_between(\n",
    "            end_date=datetime.now(tz=timezone.utc),\n",
    "            start_date=datetime.now(tz=timezone.utc) - timedelta(days=365 * 2),\n",
    "        )\n",
    "    )\n",
    "    destiny_account_id: int = Field(foreign_key=\"account.id\")\n",
    "\n",
    "\n",
    "class Withdraw(SQLModel, table=True):\n",
    "    id: Optional[int] = Field(default=None, primary_key=True)\n",
    "    amount: float = Field(\n",
    "        default_factory=lambda: fake.pyfloat(\n",
    "            positive=True, min_value=1, max_value=10000\n",
    "        )\n",
    "    )\n",
    "    timestamp: datetime = Field(\n",
    "        default_factory=lambda: fake.date_time_between(\n",
    "            end_date=datetime.now(tz=timezone.utc),\n",
    "            start_date=datetime.now(tz=timezone.utc) - timedelta(days=365 * 2),\n",
    "        )\n",
    "    )\n",
    "    source_account_id: int = Field(foreign_key=\"account.id\")\n",
    "\n",
    "\n",
    "class Transaction(SQLModel, table=True):\n",
    "    id: Optional[int] = Field(default=None, primary_key=True)\n",
    "    amount: float = Field(\n",
    "        default_factory=lambda: fake.pyfloat(\n",
    "            positive=True, min_value=1, max_value=10000\n",
    "        )\n",
    "    )\n",
    "    transaction_type: str = Field(default=\"Transfer\")\n",
    "    timestamp: datetime = Field(\n",
    "        default_factory=lambda: fake.date_time_between(\n",
    "            end_date=datetime.now(tz=timezone.utc),\n",
    "            start_date=datetime.now(tz=timezone.utc) - timedelta(days=365 * 2),\n",
    "        )\n",
    "    )\n",
    "    source_account_id: Optional[int] = Field(default=None, foreign_key=\"account.id\")\n",
    "    destiny_account_id: Optional[int] = Field(default=None, foreign_key=\"account.id\")\n",
    "\n",
    "\n",
    "class AuditLog(SQLModel, table=True):\n",
    "    id: Optional[int] = Field(default=None, primary_key=True)\n",
    "    event_type: str = Field(\n",
    "        default_factory=lambda: fake.random_element(\n",
    "            [\n",
    "                \"LOGIN\",\n",
    "                \"LOGOUT\",\n",
    "                \"UPDATED_FIRST_NAME\",\n",
    "                \"UPDATED_LAST_NAME\",\n",
    "                \"UPDATED_EMAIL\",\n",
    "                \"UPDATED_ADDRESS\",\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    ip_address: str = Field(default_factory=fake.ipv4_public)\n",
    "    user_agent: str = Field(default_factory=fake.user_agent)\n",
    "    timestamp: datetime = Field(\n",
    "        default_factory=lambda: fake.date_time_between(\n",
    "            end_date=datetime.now(tz=timezone.utc),\n",
    "            start_date=datetime.now(tz=timezone.utc) - timedelta(days=365 * 2),\n",
    "        )\n",
    "    )\n",
    "    user_id: int = Field(foreign_key=\"user.id\")\n",
    "\n",
    "\n",
    "SQLModel.metadata.create_all(db_engine)\n",
    "print(\"‚úÖ Schema built. Ready for seeding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceca5ed",
   "metadata": {},
   "source": [
    "# Data: Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d4d984a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf6db7a62204730b2cfef44d07748e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üåç New Countries (70):   0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbdf186d48f7415ab6c6d87cbc327341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üí± New Currencies (48):   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3785183949ad4ff682659752b64c375c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üèôÔ∏è New Cities (100):   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39002d2b458b4185bec0f429af8950e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üè¢ New Branches (69):   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6dd18f17638486a8573d6b2c766d0d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üë§ New Users (25392):   0%|          | 0/25392 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f746774ffb14abd9c17945b8872c55f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üè¶ New Accounts (22266):   0%|          | 0/22266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962c8bbb303240929488e7a912a9619d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üí≥ New Cards (26005):   0%|          | 0/26005 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7509775f9194760bfa1b802a7ef6fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üí∞ New Deposits (16974):   0%|          | 0/16974 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c57485531c7498cbf89b76f15d7c6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üí∏ New Withdrawals (15936):   0%|          | 0/15936 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c58e09d40644a24a7ef75364c07827c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîÑ New Transfers (11953):   0%|          | 0/11953 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0289a54e571644fba240f913ba52a849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üìã New Audit Logs (15228):   0%|          | 0/15228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ SEEDING SUCCESSFUL: System now contains 22266 accounts.\n"
     ]
    }
   ],
   "source": [
    "from sqlmodel import Session, select\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def seed_complete_system(engine):\n",
    "    # --- DYNAMIC CONFIGURATION ---\n",
    "    N_USERS = random.randint(10000, 30000)\n",
    "    N_ACCOUNTS = random.randint(10000, 25000)\n",
    "    N_CARDS = random.randint(10000, 30000)\n",
    "\n",
    "    # Granular Reference Counts\n",
    "    N_COUNTRIES, N_CURRENCIES = random.randint(30, 80), random.randint(30, 80)\n",
    "    N_CITIES, N_BRANCHES = random.randint(100, 200), random.randint(50, 100)\n",
    "\n",
    "    # Granular Operation Counts\n",
    "    N_DEPOSITS = random.randint(10000, 20000)\n",
    "    N_WITHDRAWS = random.randint(10000, 20000)\n",
    "    N_TRANSACTIONS = random.randint(10000, 30000)\n",
    "    N_AUDITS = random.randint(10000, 40000)\n",
    "\n",
    "    BATCH_SIZE = 1000\n",
    "\n",
    "    with Session(engine) as session:\n",
    "\n",
    "        def get_existing(model):\n",
    "            return session.exec(select(model)).all()\n",
    "\n",
    "        # --- 1. References (with merged logic) ---\n",
    "        # Countries\n",
    "        for _ in tqdm(range(N_COUNTRIES), desc=f\"üåç New Countries ({N_COUNTRIES})\"):\n",
    "            c = Country()\n",
    "            c_ = session.exec(select(Country).where(Country.name == c.name)).first()\n",
    "            if c_:\n",
    "                id = c_.id\n",
    "                c_.sqlmodel_update(c)\n",
    "                c_.id = id\n",
    "                session.add(c_)\n",
    "            else:\n",
    "                session.add(c)\n",
    "        session.commit()\n",
    "        all_countries = get_existing(Country)\n",
    "\n",
    "        # Currencies\n",
    "        for _ in tqdm(range(N_CURRENCIES), desc=f\"üí± New Currencies ({N_CURRENCIES})\"):\n",
    "            curr = Currency()\n",
    "            curr_ = session.exec(\n",
    "                select(Currency).where(Currency.code == curr.code)\n",
    "            ).first()\n",
    "            if curr_:\n",
    "                id = curr_.id\n",
    "                curr_.sqlmodel_update(curr)\n",
    "                curr_.id = id\n",
    "                session.add(curr_)\n",
    "            else:\n",
    "                session.add(curr)\n",
    "        session.commit()\n",
    "        all_currencies = get_existing(Currency)\n",
    "\n",
    "        # Cities\n",
    "        for _ in tqdm(range(N_CITIES), desc=f\"üèôÔ∏è New Cities ({N_CITIES})\"):\n",
    "            city = City(country_id=random.choice(all_countries).id)\n",
    "            session.merge(city)\n",
    "            session.commit()\n",
    "        all_cities = get_existing(City)\n",
    "\n",
    "        # Branches\n",
    "        for _ in tqdm(range(N_BRANCHES), desc=f\"üè¢ New Branches ({N_BRANCHES})\"):\n",
    "            br = Branch(city_id=random.choice(all_cities).id)\n",
    "            session.merge(br)\n",
    "            session.commit()\n",
    "        all_branch_ids = [b.id for b in get_existing(Branch)]\n",
    "\n",
    "        # --- 2. Users ---\n",
    "        existing_users = get_existing(User)\n",
    "        user_pool = [(u.id, f\"{u.first_name} {u.last_name}\") for u in existing_users]\n",
    "        for u in existing_users:\n",
    "            fake.unique.add_value('username', u.username)\n",
    "            fake.unique.add_value('email', u.email)\n",
    "\n",
    "        pbar_u = tqdm(total=N_USERS, desc=f\"üë§ New Users ({N_USERS})\")\n",
    "        created_u = 0\n",
    "        while created_u < N_USERS:\n",
    "            batch_size = min(BATCH_SIZE, N_USERS - created_u)\n",
    "            batch = [User() for _ in range(batch_size)]\n",
    "            session.add_all(batch)\n",
    "            session.commit()\n",
    "            user_pool.extend([(u.id, f\"{u.first_name} {u.last_name}\") for u in batch])\n",
    "            created_u += batch_size\n",
    "            pbar_u.update(batch_size)\n",
    "        pbar_u.close()\n",
    "\n",
    "        # --- 3. Accounts ---\n",
    "        # Build map for Card Holder consistency\n",
    "        account_name_map = {}\n",
    "        for acc in get_existing(Account):\n",
    "            u = session.get(User, acc.user_id)\n",
    "            account_name_map[acc.id] = (\n",
    "                f\"{u.first_name} {u.last_name}\" if u else \"Unknown\"\n",
    "            )\n",
    "\n",
    "        curr_ids = [c.id for c in all_currencies]\n",
    "        pbar_acc = tqdm(total=N_ACCOUNTS, desc=f\"üè¶ New Accounts ({N_ACCOUNTS})\")\n",
    "        for i in range(0, N_ACCOUNTS, BATCH_SIZE):\n",
    "            batch_size = min(BATCH_SIZE, N_ACCOUNTS - i)\n",
    "            batch_data = []\n",
    "            for _ in range(batch_size):\n",
    "                u_id, u_name = random.choice(user_pool)\n",
    "                acc = Account(\n",
    "                    user_id=u_id,\n",
    "                    currency_id=random.choice(curr_ids),\n",
    "                    branch_id=random.choice(all_branch_ids),\n",
    "                )\n",
    "                batch_data.append((acc, u_name))\n",
    "            session.add_all([item[0] for item in batch_data])\n",
    "            session.commit()\n",
    "            for acc, u_name in batch_data:\n",
    "                account_name_map[acc.id] = u_name\n",
    "            pbar_acc.update(batch_size)\n",
    "        pbar_acc.close()\n",
    "\n",
    "        # --- 4. Cards ---\n",
    "        all_acc_ids = list(account_name_map.keys())\n",
    "        pbar_card = tqdm(total=N_CARDS, desc=f\"üí≥ New Cards ({N_CARDS})\")\n",
    "        for i in range(0, N_CARDS, BATCH_SIZE):\n",
    "            batch_size = min(BATCH_SIZE, N_CARDS - i)\n",
    "            batch = [\n",
    "                Card(\n",
    "                    account_id=random.choice(all_acc_ids),\n",
    "                    card_holder_name=account_name_map[\n",
    "                        random.choice(all_acc_ids)\n",
    "                    ].upper(),\n",
    "                )\n",
    "                for _ in range(batch_size)\n",
    "            ]\n",
    "            session.add_all(batch)\n",
    "            session.commit()\n",
    "            pbar_card.update(batch_size)\n",
    "        pbar_card.close()\n",
    "\n",
    "        # --- 5. Financial Operations (Split) ---\n",
    "        # Deposits\n",
    "        pbar_dep = tqdm(total=N_DEPOSITS, desc=f\"üí∞ New Deposits ({N_DEPOSITS})\")\n",
    "        for i in range(0, N_DEPOSITS, BATCH_SIZE):\n",
    "            batch_size = min(BATCH_SIZE, N_DEPOSITS - i)\n",
    "            session.add_all(\n",
    "                [\n",
    "                    Deposit(destiny_account_id=random.choice(all_acc_ids))\n",
    "                    for _ in range(batch_size)\n",
    "                ]\n",
    "            )\n",
    "            session.commit()\n",
    "            pbar_dep.update(batch_size)\n",
    "        pbar_dep.close()\n",
    "\n",
    "        # Withdrawals\n",
    "        pbar_wit = tqdm(total=N_WITHDRAWS, desc=f\"üí∏ New Withdrawals ({N_WITHDRAWS})\")\n",
    "        for i in range(0, N_WITHDRAWS, BATCH_SIZE):\n",
    "            batch_size = min(BATCH_SIZE, N_WITHDRAWS - i)\n",
    "            session.add_all(\n",
    "                [\n",
    "                    Withdraw(source_account_id=random.choice(all_acc_ids))\n",
    "                    for _ in range(batch_size)\n",
    "                ]\n",
    "            )\n",
    "            session.commit()\n",
    "            pbar_wit.update(batch_size)\n",
    "        pbar_wit.close()\n",
    "\n",
    "        # Transfers\n",
    "        pbar_tra = tqdm(\n",
    "            total=N_TRANSACTIONS, desc=f\"üîÑ New Transfers ({N_TRANSACTIONS})\"\n",
    "        )\n",
    "        for i in range(0, N_TRANSACTIONS, BATCH_SIZE):\n",
    "            batch_size = min(BATCH_SIZE, N_TRANSACTIONS - i)\n",
    "            session.add_all(\n",
    "                [\n",
    "                    Transaction(\n",
    "                        source_account_id=random.choice(all_acc_ids),\n",
    "                        destiny_account_id=random.choice(all_acc_ids),\n",
    "                    )\n",
    "                    for _ in range(batch_size)\n",
    "                ]\n",
    "            )\n",
    "            session.commit()\n",
    "            pbar_tra.update(batch_size)\n",
    "        pbar_tra.close()\n",
    "\n",
    "        # --- 6. Audit Logs ---\n",
    "        u_ids = [u[0] for u in user_pool]\n",
    "        pbar_aud = tqdm(total=N_AUDITS, desc=f\"üìã New Audit Logs ({N_AUDITS})\")\n",
    "        for i in range(0, N_AUDITS, BATCH_SIZE):\n",
    "            batch_size = min(BATCH_SIZE, N_AUDITS - i)\n",
    "            session.add_all(\n",
    "                [AuditLog(user_id=random.choice(u_ids)) for _ in range(batch_size)]\n",
    "            )\n",
    "            session.commit()\n",
    "            pbar_aud.update(batch_size)\n",
    "        pbar_aud.close()\n",
    "\n",
    "    print(f\"\\n‚úÖ SEEDING SUCCESSFUL: System now contains {len(all_acc_ids)} accounts.\")\n",
    "\n",
    "\n",
    "seed_complete_system(db_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07931a52",
   "metadata": {},
   "source": [
    "# Consistency: Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c0aa938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626a264330014880bc0e5faab2355679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aggregating:   0%|          | 0/22266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Reconciliation complete. All balances match the transaction history.\n"
     ]
    }
   ],
   "source": [
    "from sqlmodel import select, func\n",
    "\n",
    "def synchronize_all_balances(engine):\n",
    "    with Session(engine) as session:\n",
    "        # Get all accounts to process\n",
    "        accounts = session.exec(select(Account)).all()\n",
    "        \n",
    "        # print(\"üîÑ Calculating consistent balances based on ledger history...\")\n",
    "        \n",
    "        for acc in tqdm(accounts, desc=\"Aggregating\"):\n",
    "            # 1. Credits (Money In)\n",
    "            sum_deposits = session.exec(\n",
    "                select(func.sum(Deposit.amount)).where(Deposit.destiny_account_id == acc.id)\n",
    "            ).one() or 0.0\n",
    "            \n",
    "            sum_transfers_in = session.exec(\n",
    "                select(func.sum(Transaction.amount)).where(Transaction.destiny_account_id == acc.id)\n",
    "            ).one() or 0.0\n",
    "\n",
    "            # 2. Debits (Money Out)\n",
    "            sum_withdraws = session.exec(\n",
    "                select(func.sum(Withdraw.amount)).where(Withdraw.source_account_id == acc.id)\n",
    "            ).one() or 0.0\n",
    "            \n",
    "            sum_transfers_out = session.exec(\n",
    "                select(func.sum(Transaction.amount)).where(Transaction.source_account_id == acc.id)\n",
    "            ).one() or 0.0\n",
    "\n",
    "            # 3. Update the Account Balance\n",
    "            # Formula: (Inbound) - (Outbound)\n",
    "            acc.balance = (sum_deposits + sum_transfers_in) - (sum_withdraws + sum_transfers_out)\n",
    "            \n",
    "            session.add(acc)\n",
    "        \n",
    "        session.commit()\n",
    "        print(\"\\n‚úÖ Reconciliation complete. All balances match the transaction history.\")\n",
    "\n",
    "# Run the synchronization\n",
    "synchronize_all_balances(db_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f0285f",
   "metadata": {},
   "source": [
    "# Validation: Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d541e566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VALIDATION REPORT FOR ACCOUNT: GB50NSOT37451520037828\n",
      "User ID: 17310\n",
      "============================================================\n",
      "TYPE                 | COUNT    |    TOTAL AMOUNT\n",
      "------------------------------------------------------------\n",
      "Deposits (+)         | 1        |         6122.12\n",
      "Transfers In (+)     | 1        |         5885.21\n",
      "Withdrawals (-)      | 0        |            0.00\n",
      "Transfers Out (-)    | 0        |            0.00\n",
      "------------------------------------------------------------\n",
      "TOTAL CALCULATED                |        12007.33\n",
      "DATABASE BALANCE                |        12007.33\n",
      "VERIFICATION                    |       ‚úÖ MATCH\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sqlmodel import select, func\n",
    "\n",
    "def validate_random_account(engine):\n",
    "    with Session(engine) as session:\n",
    "        # 1. Pick a random account that actually has some activity\n",
    "        # We'll look for accounts that have at least one deposit to make it interesting\n",
    "        stmt = select(Account).where(Account.id.in_(select(Deposit.destiny_account_id)))\n",
    "        active_accounts = session.exec(stmt).all()\n",
    "        \n",
    "        if not active_accounts:\n",
    "            print(\"‚ùå No active accounts found. Please ensure the database is seeded.\")\n",
    "            return\n",
    "\n",
    "        target_acc = random.choice(active_accounts)\n",
    "        acc_id = target_acc.id\n",
    "\n",
    "        # 2. Fetch all individual records\n",
    "        deps = session.exec(select(Deposit).where(Deposit.destiny_account_id == acc_id)).all()\n",
    "        wits = session.exec(select(Withdraw).where(Withdraw.source_account_id == acc_id)).all()\n",
    "        tx_in = session.exec(select(Transaction).where(Transaction.destiny_account_id == acc_id)).all()\n",
    "        tx_out = session.exec(select(Transaction).where(Transaction.source_account_id == acc_id)).all()\n",
    "\n",
    "        # 3. Calculate Aggregates\n",
    "        sum_deps = sum(d.amount for d in deps)\n",
    "        sum_wits = sum(w.amount for w in wits)\n",
    "        sum_tx_in = sum(t.amount for t in tx_in)\n",
    "        sum_tx_out = sum(t.amount for t in tx_out)\n",
    "        \n",
    "        calculated_balance = (sum_deps + sum_tx_in) - (sum_wits + sum_tx_out)\n",
    "\n",
    "        # 4. PRINT REPORT\n",
    "        print(\"=\"*60)\n",
    "        print(f\"VALIDATION REPORT FOR ACCOUNT: {target_acc.account_number}\")\n",
    "        print(f\"User ID: {target_acc.user_id}\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        print(f\"{'TYPE':<20} | {'COUNT':<8} | {'TOTAL AMOUNT':>15}\")\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"{'Deposits (+)':<20} | {len(deps):<8} | {sum_deps:>15.2f}\")\n",
    "        print(f\"{'Transfers In (+)':<20} | {len(tx_in):<8} | {sum_tx_in:>15.2f}\")\n",
    "        print(f\"{'Withdrawals (-)':<20} | {len(wits):<8} | {sum_wits:>15.2f}\")\n",
    "        print(f\"{'Transfers Out (-)':<20} | {len(tx_out):<8} | {sum_tx_out:>15.2f}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        print(f\"{'TOTAL CALCULATED':<31} | {calculated_balance:>15.2f}\")\n",
    "        print(f\"{'DATABASE BALANCE':<31} | {target_acc.balance:>15.2f}\")\n",
    "        \n",
    "        diff = abs(calculated_balance - target_acc.balance)\n",
    "        status = f\"{'      ‚úÖ MATCH'}\" if diff < 0.01 else f\"      ‚ùå DISCREPANCY ({diff:.2f})\"\n",
    "        print(f\"{'VERIFICATION':<31} | {status}\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        # # 5. Optional: Print top 5 specific movements\n",
    "        # if deps or tx_in or wits or tx_out:\n",
    "        #     print(\"\\nRecent Ledger Activity (First 5):\")\n",
    "        #     for d in deps[:2]: print(f\"  [+] Deposit:    +{d.amount:>10.2f}\")\n",
    "        #     for t in tx_in[:2]: print(f\"  [+] Transfer:   +{t.amount:>10.2f}\")\n",
    "        #     for w in wits[:2]: print(f\"  [-] Withdraw:   -{w.amount:>10.2f}\")\n",
    "        #     for t in tx_out[:2]: print(f\"  [-] Transfer:   -{t.amount:>10.2f}\")\n",
    "\n",
    "# Execute validation\n",
    "validate_random_account(db_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c783831",
   "metadata": {},
   "source": [
    "# Schema: e-commerce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ed0993c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è PostgreSQL Database wiped clean.\n",
      "‚úÖ Schema built. Ready for seeding.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "import faker_commerce\n",
    "from typing import Optional, cast\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from faker import Faker\n",
    "from mimesis import Generic\n",
    "from sqlmodel import Field, SQLModel, Session, create_engine, text\n",
    "from sqlalchemy.orm import registry\n",
    "from sqlalchemy.orm import declared_attr  # Import the missing attribute\n",
    "\n",
    "mim_generic = Generic(locale=\"en\")\n",
    "fake = Faker()\n",
    "fake.add_provider(faker_commerce.Provider)\n",
    "\n",
    "db_url = f\"postgresql+psycopg2://{POSTGRESQL_INIT_USER}:{POSTGRESQL_INIT_PASSWORD}@postgres.{POSTGRESQL_VPN_SELF_HOSTNAME}:{POSTGRESQL_BASE_PORT}/{DatabasesList.ECOMMERCE.value}\"\n",
    "db_engine = create_engine(db_url)\n",
    "\n",
    "with Session(db_engine) as session:\n",
    "    session.exec(text(\"DROP SCHEMA public CASCADE;\"))\n",
    "    session.exec(text(\"CREATE SCHEMA public;\"))\n",
    "    # session.exec(text(\"GRANT ALL ON SCHEMA public TO public;\"))\n",
    "    session.exec(text(f\"GRANT ALL ON SCHEMA public TO {POSTGRESQL_INIT_USER};\"))\n",
    "    session.commit()\n",
    "print(\"üóëÔ∏è PostgreSQL Database wiped clean.\")\n",
    "\n",
    "SQLModel.metadata.clear()\n",
    "if hasattr(SQLModel, \"registry\"):\n",
    "    SQLModel.registry.dispose()\n",
    "registry().dispose()\n",
    "\n",
    "\n",
    "# --- 1. User & Payment ---\n",
    "\n",
    "\n",
    "# Regex to convert CamelCase to snake_case\n",
    "def to_snake_case(name: str) -> str:\n",
    "    return re.sub(r\"(?<!^)(?=[A-Z])\", \"_\", name).lower()\n",
    "\n",
    "\n",
    "class SnakeCaseModel(SQLModel):\n",
    "    @declared_attr\n",
    "    def __tablename__(cls) -> str:\n",
    "        return to_snake_case(cls.__name__)\n",
    "\n",
    "\n",
    "# --- 1. User & Payment ---\n",
    "\n",
    "\n",
    "class User(SnakeCaseModel, table=True):\n",
    "    id: Optional[int] = Field(default=None, primary_key=True)\n",
    "    username: str = Field(\n",
    "        default_factory=lambda: cast(Faker, fake.unique).user_name(), unique=True\n",
    "    )\n",
    "    email: str = Field(\n",
    "        default_factory=lambda: cast(Faker, fake.unique).email(), unique=True\n",
    "    )\n",
    "    password: str = Field(\n",
    "        default_factory=lambda: mim_generic.person.password(hashed=True)\n",
    "    )\n",
    "    first_name: str = Field(default_factory=mim_generic.person.first_name)\n",
    "    last_name: str = Field(default_factory=mim_generic.person.last_name)\n",
    "    birthdate: datetime = Field(\n",
    "        default_factory=lambda: fake.date_of_birth(minimum_age=18, maximum_age=90)\n",
    "    )\n",
    "    created_at: datetime = Field(\n",
    "        default_factory=lambda: fake.date_time_between(\n",
    "            end_date=datetime.now(tz=timezone.utc),\n",
    "            start_date=datetime.now(tz=timezone.utc) - timedelta(days=365 * 3),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "class Card(SnakeCaseModel, table=True):\n",
    "    id: Optional[int] = Field(default=None, primary_key=True)\n",
    "    card_number: str = Field(\n",
    "        default_factory=lambda: cast(Faker, fake.unique).credit_card_number()\n",
    "    )\n",
    "    expiry: str = Field(default_factory=fake.credit_card_expire)\n",
    "    cvv: str = Field(default_factory=fake.credit_card_security_code)\n",
    "    user_id: int = Field(foreign_key=\"user.id\")\n",
    "    # Added creation_date\n",
    "    created_at: datetime = Field(\n",
    "        default_factory=lambda: fake.date_time_between(\n",
    "            end_date=datetime.now(tz=timezone.utc),\n",
    "            start_date=datetime.now(tz=timezone.utc) - timedelta(days=365 * 3),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# --- 2. Catalog ---\n",
    "\n",
    "\n",
    "class Category(SnakeCaseModel, table=True):\n",
    "    id: Optional[int] = Field(default=None, primary_key=True)\n",
    "    name: str = Field(\n",
    "        default_factory=lambda: cast(Faker, fake.unique).bothify(\n",
    "            f\"{cast(faker_commerce.Provider, fake).ecommerce_category()} {cast(faker_commerce.Provider, fake).ecommerce_material()} %%%%\"\n",
    "        ),\n",
    "        unique=True,\n",
    "    )\n",
    "\n",
    "\n",
    "class Product(SnakeCaseModel, table=True):\n",
    "    id: Optional[int] = Field(default=None, primary_key=True)\n",
    "    name: str = Field(\n",
    "        default_factory=cast(faker_commerce.Provider, fake).ecommerce_name\n",
    "    )\n",
    "    description: str = Field(default_factory=fake.sentence)\n",
    "    sku: str = Field(\n",
    "        default_factory=lambda: cast(Faker, fake.unique).ean8(), unique=True\n",
    "    )\n",
    "    price: float = Field(default_factory=lambda: round(random.uniform(1.0, 1000.0), 2))\n",
    "\n",
    "\n",
    "class CategoryProduct(SnakeCaseModel, table=True):\n",
    "    category_id: int = Field(foreign_key=\"category.id\", primary_key=True)\n",
    "    product_id: int = Field(foreign_key=\"product.id\", primary_key=True)\n",
    "\n",
    "\n",
    "# --- 3. Shopping Cart ---\n",
    "\n",
    "\n",
    "class ShoppingCart(SnakeCaseModel, table=True):\n",
    "    # id: Optional[int] = Field(default=None, primary_key=True)\n",
    "    user_id: int = Field(foreign_key=\"user.id\", primary_key=True)\n",
    "    # status: str = Field(\n",
    "    #     default_factory=lambda: random.choice([\"ACTIVE\", \"ABANDONED\"])\n",
    "    # )\n",
    "    created_at: datetime = Field(\n",
    "        default_factory=lambda: fake.date_time_between(\n",
    "            end_date=datetime.now(tz=timezone.utc),\n",
    "            start_date=datetime.now(tz=timezone.utc) - timedelta(days=365 * 3),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "class CartProduct(SnakeCaseModel, table=True):\n",
    "    cart_id: int = Field(foreign_key=\"shopping_cart.user_id\", primary_key=True)\n",
    "    product_id: int = Field(foreign_key=\"product.id\", primary_key=True)\n",
    "    # Added quantity and creation date\n",
    "    quantity: int = Field(default_factory=lambda: random.randint(1, 5))\n",
    "    created_at: datetime = Field(\n",
    "        default_factory=lambda: fake.date_time_between(\n",
    "            end_date=datetime.now(tz=timezone.utc),\n",
    "            start_date=datetime.now(tz=timezone.utc) - timedelta(days=365 * 3),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# --- 4. Orders & Fulfillment ---\n",
    "\n",
    "\n",
    "class Order(SnakeCaseModel, table=True):\n",
    "    id: Optional[int] = Field(default=None, primary_key=True)\n",
    "    status: str = Field(\n",
    "        default_factory=lambda: random.choice([\"PENDING\", \"COMPLETED\", \"CANCELLED\"])\n",
    "    )\n",
    "    user_id: int = Field(foreign_key=\"user.id\")\n",
    "    # Added creation_date\n",
    "    created_at: datetime = Field(\n",
    "        default_factory=lambda: fake.date_time_between(\n",
    "            end_date=datetime.now(tz=timezone.utc),\n",
    "            start_date=datetime.now(tz=timezone.utc) - timedelta(days=365 * 3),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "class OrderProduct(SnakeCaseModel, table=True):\n",
    "    order_id: int = Field(foreign_key=\"order.id\", primary_key=True)\n",
    "    product_id: int = Field(foreign_key=\"product.id\", primary_key=True)\n",
    "    # Added quantity and creation date\n",
    "    quantity: int = Field(default_factory=lambda: random.randint(1, 5))\n",
    "    unit_price: float = Field(default=0.0)\n",
    "    created_at: datetime = Field(\n",
    "        default_factory=lambda: fake.date_time_between(\n",
    "            end_date=datetime.now(tz=timezone.utc),\n",
    "            start_date=datetime.now(tz=timezone.utc) - timedelta(days=365 * 3),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "class Payment(SnakeCaseModel, table=True):\n",
    "    id: Optional[int] = Field(default=None, primary_key=True)\n",
    "    amount: float = Field(default=0.0)\n",
    "    transaction_id: str = Field(\n",
    "        default_factory=lambda: cast(Faker, fake.unique).uuid4()\n",
    "    )\n",
    "    order_id: int = Field(foreign_key=\"order.id\", unique=True)\n",
    "    card_id: int = Field(foreign_key=\"card.id\")\n",
    "    created_at: datetime = Field(\n",
    "        default_factory=lambda: fake.date_time_between(\n",
    "            end_date=datetime.now(tz=timezone.utc),\n",
    "            start_date=datetime.now(tz=timezone.utc) - timedelta(days=365 * 3),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "class Shipment(SnakeCaseModel, table=True):\n",
    "    id: Optional[int] = Field(default=None, primary_key=True)\n",
    "    tracking_number: str = Field(\n",
    "        default_factory=lambda: cast(Faker, fake.unique)\n",
    "        .bothify(\"??-#########-??\")\n",
    "        .upper()\n",
    "    )\n",
    "    carrier: str = Field(default_factory=lambda: random.choice([\"DHL\", \"UPS\", \"FedEx\"]))\n",
    "    shipping_address: str = Field(default_factory=mim_generic.address.address)\n",
    "    order_id: int = Field(foreign_key=\"order.id\", unique=True)\n",
    "    status: str = Field(\n",
    "        default_factory=lambda: random.choice(\n",
    "            [\"PROCESSING\", \"SHIPPED\", \"IN TRANSIT\", \"DELIVERED\"]\n",
    "        )\n",
    "    )\n",
    "    send_date: Optional[datetime] = Field(\n",
    "        default=None,\n",
    "    )\n",
    "    received_date: Optional[datetime] = Field(default=None)\n",
    "    created_at: datetime = Field(\n",
    "        default_factory=lambda: fake.date_time_between(\n",
    "            end_date=datetime.now(tz=timezone.utc),\n",
    "            start_date=datetime.now(tz=timezone.utc) - timedelta(days=365 * 3),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "SQLModel.metadata.create_all(db_engine)\n",
    "print(\"‚úÖ Schema built. Ready for seeding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e70cd7",
   "metadata": {},
   "source": [
    "# Data: e-commerce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "662f6085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdfefab258844a38ad47ea6da0cc25d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üè∑Ô∏è Categories:   0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983fd6d32c0a48568cf4d0266af68b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üì¶ Products:   0%|          | 0/662 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147b70e472464ac59ec13fb576a05cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîó Category Products Mapping:   0%|          | 0/662 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75208ea3a6646ed9e0888038640ed04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üë§ Users:   0%|          | 0/5182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33adf60050d94971ac39fce98ce0d55c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üí≥ Cards & Carts:   0%|          | 0/5182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81889ed014e41ce8dc500d9a7423399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üõí Cart Items:   0%|          | 0/5182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09924e0b657546f9af5efd6779c2f77b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üìù Orders:   0%|          | 0/10736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c664a77d79c48469f7cbced094eff68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üõí Shipments & Payments:   0%|          | 0/10736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ DATABASE SEEDED: 5182 Users, 662 Products, and 10736 Orders created.\n"
     ]
    }
   ],
   "source": [
    "from ast import Or\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from sqlmodel import Session, select\n",
    "\n",
    "\n",
    "def seed_ecommerce_system(engine):\n",
    "    # --- DYNAMIC CONFIGURATION ---\n",
    "    # Adjust ranges as needed for your testing scale\n",
    "    N_USERS = random.randint(5000, 10000)\n",
    "    N_CATEGORIES = random.randint(100, 200)\n",
    "    N_PRODUCTS = random.randint(500, 1000)\n",
    "    MIN_CARDS_PER_USER = 0\n",
    "    MAX_CARDS_PER_USER = 10\n",
    "    MIN_PROD_PER_CART = 0\n",
    "    MAX_PROD_PER_CART = 10\n",
    "    MIN_PROD_PER_ORDER = 0\n",
    "    MAX_PROD_PER_ORDER = 10\n",
    "    MIN_PROD_QUANT_IN_ORDER = 1\n",
    "    MAX_PROD_QUANT_IN_ORDER = 10\n",
    "    N_ORDERS = random.randint(8000, 16000)\n",
    "\n",
    "    with Session(engine) as session:\n",
    "\n",
    "        for _ in tqdm(range(N_CATEGORIES), desc=\"üè∑Ô∏è Categories\"):\n",
    "            session.add(Category())\n",
    "        session.commit()\n",
    "        category_ids = session.exec(select(Category.id)).all()\n",
    "\n",
    "        for i in tqdm(range(0, N_PRODUCTS), desc=\"üì¶ Products\"):\n",
    "            session.add(Product())\n",
    "        session.commit()\n",
    "        product_ids = session.exec(select(Product.id)).all()\n",
    "\n",
    "        for p_id in tqdm(product_ids, desc=\"üîó Category Products Mapping\"):\n",
    "            chosen_cats = random.sample(category_ids, k=random.randint(1, 10))\n",
    "            for c_id in chosen_cats:\n",
    "                session.add(CategoryProduct(category_id=c_id, product_id=p_id))\n",
    "        session.commit()\n",
    "\n",
    "        for i in tqdm(range(0, N_USERS), desc=\"üë§ Users\"):\n",
    "            session.add(User())\n",
    "        session.commit()\n",
    "        user_ids = session.exec(select(User.id)).all()\n",
    "\n",
    "        for u_id in tqdm(user_ids, desc=\"üí≥ Cards & Carts\"):\n",
    "            session.add(ShoppingCart(user_id=u_id))\n",
    "            for _ in range(random.randint(MIN_CARDS_PER_USER, MAX_CARDS_PER_USER)):\n",
    "                session.add(Card(user_id=u_id))\n",
    "        session.commit()\n",
    "\n",
    "        cart_ids = session.exec(select(ShoppingCart.user_id)).all()\n",
    "\n",
    "        for c_id in tqdm(cart_ids, desc=\"üõí Cart Items\"):\n",
    "            cart_prod_ids = random.sample(\n",
    "                product_ids, random.randint(MIN_PROD_PER_CART, MAX_PROD_PER_CART)\n",
    "            )\n",
    "            card_products = [\n",
    "                CartProduct(cart_id=c_id, product_id=prod_id)\n",
    "                for prod_id in cart_prod_ids\n",
    "            ]\n",
    "            session.add_all(card_products)\n",
    "        session.commit()\n",
    "\n",
    "        for _ in tqdm(range(0, N_ORDERS), desc=\"üìù Orders\"):\n",
    "            u_id = random.choice(user_ids)\n",
    "            order = Order(user_id=u_id)\n",
    "            session.add(order)\n",
    "        session.commit()\n",
    "\n",
    "        order_ids = session.exec(select(Order.id)).all()\n",
    "        for order_id in tqdm(order_ids, desc=\"üõí Shipments & Payments\"):\n",
    "            prod_ids = random.sample(\n",
    "                product_ids, random.randint(MIN_PROD_PER_ORDER, MAX_PROD_PER_ORDER)\n",
    "            )\n",
    "            for prod_id in prod_ids:\n",
    "                session.add(\n",
    "                    OrderProduct(\n",
    "                        order_id=order_id,\n",
    "                        product_id=prod_id,\n",
    "                        quantity=random.randint(\n",
    "                            MIN_PROD_QUANT_IN_ORDER, MAX_PROD_QUANT_IN_ORDER\n",
    "                        ),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            # Create Payment if order is not Pending/Cancelled (mostly)\n",
    "            if order.status in [\"COMPLETED\", \"CANCELLED\"]:\n",
    "                user_card_id = None\n",
    "                user_cards = session.exec(\n",
    "                    select(Card.id)\n",
    "                    .join(User, User.id == Card.user_id)\n",
    "                    .join(Order, Order.user_id == User.id)\n",
    "                    .where(Order.id == order_id)\n",
    "                ).all()\n",
    "                if user_cards:\n",
    "                    user_card_id = random.choice(user_cards)\n",
    "                else:\n",
    "                    card = Card(user_id=u_id)\n",
    "                    session.add(card)\n",
    "                    session.flush()\n",
    "                    user_card_id = card.id\n",
    "\n",
    "                # Create Payment\n",
    "                payment = Payment(\n",
    "                    order_id=order_id,\n",
    "                    amount=0,\n",
    "                    card_id=user_card_id,\n",
    "                )\n",
    "                session.add(payment)\n",
    "                session.flush()\n",
    "\n",
    "                # Create Shipment\n",
    "                shipment_status = random.choice(\n",
    "                    [\"PROCESSING\", \"SHIPPED\", \"IN TRANSIT\", \"DELIVERED\"]\n",
    "                )\n",
    "                received_date = None\n",
    "                send_date = None\n",
    "                creation_date = fake.date_time_between(\n",
    "                    start_date=datetime.now(tz=timezone.utc) - timedelta(days=365 * 3),\n",
    "                    end_date=datetime.now(tz=timezone.utc),\n",
    "                )\n",
    "                if shipment_status in [\"SHIPPED\", \"IN TRANSIT\", \"DELIVERED\"]:\n",
    "                    fake.time_delta(end_datetime=creation_date)\n",
    "                    send_date = creation_date + fake.time_delta(\n",
    "                        end_datetime=creation_date\n",
    "                    )\n",
    "                if shipment_status in [\"DELIVERED\"]:\n",
    "                    received_date = send_date + fake.time_delta(end_datetime=send_date)\n",
    "\n",
    "                shipment = Shipment(\n",
    "                    order_id=order_id,\n",
    "                    status=shipment_status,\n",
    "                    created_at=creation_date,\n",
    "                    send_date=send_date,\n",
    "                    received_date=received_date,\n",
    "                )\n",
    "                session.add(shipment)\n",
    "                session.flush()\n",
    "            session.flush()\n",
    "        session.commit()\n",
    "\n",
    "    print(\n",
    "        f\"\\n‚úÖ DATABASE SEEDED: {N_USERS} Users, {N_PRODUCTS} Products, and {N_ORDERS} Orders created.\"\n",
    "    )\n",
    "\n",
    "\n",
    "seed_ecommerce_system(db_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a28cc29",
   "metadata": {},
   "source": [
    "# Consistency: e-commerce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ec90376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219557b8b0c54dbaa752823fd13587a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating unit prices:   0%|          | 0/53677 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e27cfb1a2941bb87156cce16719629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating totals:   0%|          | 0/10736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Payment amounts synchronized with Order totals.\n"
     ]
    }
   ],
   "source": [
    "from sqlmodel import Session, select\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def synchronize_financial_data(engine):\n",
    "    with Session(engine) as session:\n",
    "        # 1. Map Products to Prices for quick lookup\n",
    "        # print(\"Mapping product prices...\")\n",
    "        product_price_map = {p.id: p.price for p in session.exec(select(Product)).all()}\n",
    "        \n",
    "        # 2. Update OrderProduct unit prices to match Product catalog\n",
    "        order_products = session.exec(select(OrderProduct)).all()\n",
    "        # print(f\"Syncing {len(order_products)} order line items...\")\n",
    "        for op in tqdm(order_products, desc=\"Updating unit prices\"):\n",
    "            if op.product_id in product_price_map:\n",
    "                op.unit_price = product_price_map[op.product_id]\n",
    "                session.add(op)\n",
    "            session.flush()\n",
    "        \n",
    "        session.commit()\n",
    "        # print(\"‚úÖ Unit prices synchronized with Product catalog.\")\n",
    "\n",
    "        # 3. Compute Order Totals and Update Payments\n",
    "        # We fetch orders and their related payments and line items\n",
    "        all_orders = session.exec(select(Order)).all()\n",
    "        \n",
    "        # print(f\"Recomputing totals for {len(all_orders)} orders...\")\n",
    "        for order in tqdm(all_orders, desc=\"Calculating totals\"):\n",
    "            # Get all items for this specific order\n",
    "            items = session.exec(\n",
    "                select(OrderProduct).where(OrderProduct.order_id == order.id)\n",
    "            ).all()\n",
    "            \n",
    "            # Calculate total: sum(quantity * unit_price)\n",
    "            order_total = sum((item.quantity * item.unit_price) for item in items)\n",
    "            order_total = round(order_total, 2)\n",
    "            \n",
    "            # Find the corresponding payment for this order\n",
    "            payment = session.exec(\n",
    "                select(Payment).where(Payment.order_id == order.id)\n",
    "            ).first()\n",
    "            \n",
    "            if payment:\n",
    "                payment.amount = order_total\n",
    "                session.add(payment)\n",
    "            \n",
    "            # Optional: If you had a 'total_price' field in the Order table, \n",
    "            # you would update it here: order.total_price = order_total\n",
    "            \n",
    "        session.commit()\n",
    "        print(\"\\n‚úÖ Payment amounts synchronized with Order totals.\")\n",
    "\n",
    "# Execute the sync\n",
    "synchronize_financial_data(db_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c267796a",
   "metadata": {},
   "source": [
    "# Validation: e-commerce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e6c5bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîç VALIDATION REPORT FOR ORDER ID: 5137\n",
      "Customer User ID: 2606 | Status: PENDING\n",
      "======================================================================\n",
      "Product ID   | Qty   |   Unit Price |   Catalog Price |     Subtotal\n",
      "----------------------------------------------------------------------\n",
      "34           | 6     |        49.51 |           49.51 ‚úÖ |       297.06\n",
      "242          | 7     |       972.26 |          972.26 ‚úÖ |      6805.82\n",
      "496          | 4     |       781.41 |          781.41 ‚úÖ |      3125.64\n",
      "621          | 1     |       537.98 |          537.98 ‚úÖ |       537.98\n",
      "----------------------------------------------------------------------\n",
      "TOTAL CALCULATED FROM ITEMS                      |     10766.50\n",
      "PAYMENT REGISTERED (DB)                          |         0.00\n",
      "======================================================================\n",
      "FINAL CHECKS:\n",
      "1. Catalog Price Sync:  ‚úÖ PASS\n",
      "2. Payment Consistency: ‚ùå FAIL (Diff: 10766.50)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sqlmodel import Session, select\n",
    "\n",
    "def validate_ecommerce_data(engine):\n",
    "    with Session(engine) as session:\n",
    "        # 1. Pick a random order that has items\n",
    "        # Using a subquery to ensure we select an order that actually has OrderProducts\n",
    "        order_ids_with_items = session.exec(select(OrderProduct.order_id).distinct()).all()\n",
    "        \n",
    "        if not order_ids_with_items:\n",
    "            print(\"‚ùå No orders with products found. Please seed the database first.\")\n",
    "            return\n",
    "\n",
    "        random_order_id = random.choice(order_ids_with_items)\n",
    "        order = session.get(Order, random_order_id)\n",
    "        \n",
    "        # 2. Fetch related data\n",
    "        order_items = session.exec(\n",
    "            select(OrderProduct).where(OrderProduct.order_id == order.id)\n",
    "        ).all()\n",
    "        \n",
    "        payment = session.exec(\n",
    "            select(Payment).where(Payment.order_id == order.id)\n",
    "        ).first()\n",
    "\n",
    "        # 3. Validation Logic\n",
    "        print(\"=\"*70)\n",
    "        print(f\"üîç VALIDATION REPORT FOR ORDER ID: {order.id}\")\n",
    "        print(f\"Customer User ID: {order.user_id} | Status: {order.status}\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"{'Product ID':<12} | {'Qty':<5} | {'Unit Price':>12} | {'Catalog Price':>15} | {'Subtotal':>12}\")\n",
    "        print(\"-\" * 70)\n",
    "\n",
    "        calculated_order_total = 0.0\n",
    "        price_mismatch = False\n",
    "\n",
    "        for item in order_items:\n",
    "            # Cross-reference with Product table\n",
    "            product = session.get(Product, item.product_id)\n",
    "            catalog_price = product.price if product else 0.0\n",
    "            subtotal = item.quantity * item.unit_price\n",
    "            calculated_order_total += subtotal\n",
    "            \n",
    "            # Check for price discrepancies\n",
    "            match_icon = \"‚úÖ\" if abs(item.unit_price - catalog_price) < 0.01 else \"‚ùå\"\n",
    "            if match_icon == \"‚ùå\": price_mismatch = True\n",
    "            \n",
    "            print(f\"{item.product_id:<12} | {item.quantity:<5} | {item.unit_price:>12.2f} | {catalog_price:>15.2f} {match_icon} | {subtotal:>12.2f}\")\n",
    "\n",
    "        calculated_order_total = round(calculated_order_total, 2)\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # 4. Final Verification\n",
    "        payment_amount = payment.amount if payment else 0.0\n",
    "        payment_diff = abs(calculated_order_total - payment_amount)\n",
    "        \n",
    "        print(f\"{'TOTAL CALCULATED FROM ITEMS':<48} | {calculated_order_total:>12.2f}\")\n",
    "        print(f\"{'PAYMENT REGISTERED (DB)':<48} | {payment_amount:>12.2f}\")\n",
    "        \n",
    "        # Result Summary\n",
    "        print(\"=\"*70)\n",
    "        print(\"FINAL CHECKS:\")\n",
    "        \n",
    "        price_status = \"‚úÖ PASS\" if not price_mismatch else \"‚ùå FAIL (Catalog mismatch)\"\n",
    "        total_status = \"‚úÖ PASS\" if payment_diff < 0.01 else f\"‚ùå FAIL (Diff: {payment_diff:.2f})\"\n",
    "        \n",
    "        print(f\"1. Catalog Price Sync:  {price_status}\")\n",
    "        print(f\"2. Payment Consistency: {total_status}\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "# Execute the validation\n",
    "validate_ecommerce_data(db_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48642a56",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6e39edff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import StrEnum\n",
    "\n",
    "\n",
    "class SQLRequirement(StrEnum):\n",
    "    AGGREGATION = \"Must include aggregation functions (SUM, AVG, COUNT, etc.).\"\n",
    "    WINDOWING = \"Must include partitioning and window functions (RANK, DENSE_RANK, ROW_NUMBER, etc.).\"\n",
    "    ORDER = \"Must user ORDER BY to sort by specified criteria.\"\n",
    "    LIMIT_OFFSET = (\n",
    "        \"Must use LIMIT and OFFSET to return a specific slice of the results.\"\n",
    "    )\n",
    "    SUBQUERY = \"Must utilize a subquery (correlated or non-correlated) in a WHERE or HAVING clause.\"\n",
    "    CTE = \"The query must be structured using at least one Common Table Expression (WITH clause).\"\n",
    "    JOIN = \"The query must include at least one JOIN clause (LEFT JOIN, RIGHT JOIN, INNER JOIN, JOIN, etc.)\"\n",
    "    UNION = (\n",
    "        \"Requires the use of UNION or UNION ALL to combine disparate operation tables.\"\n",
    "    )\n",
    "    INTERSECTION = (\n",
    "        \"Must use INTERSECT to find common entities across different event types.\"\n",
    "    )\n",
    "    TEMPORAL = \"Must use SQL date functions (EXTRACT, DATE_PART, or INTERVAL).\"\n",
    "    CASE_LOGIC = \"Must use a CASE statement to create conditional categories (e.g., risk levels).\"\n",
    "    HAVING = \"Must use a HAVING clause to filter grouped results.\"\n",
    "    NULL_HANDLING = \"Must use COALESCE or IS NULL to manage optional or missing values.\"\n",
    "    STRING_OP = \"Must use string functions (LIKE, CONCAT, or SUBSTR) for formatting or filtering.\"\n",
    "    EXCEPT_LOGIC = \"Must use the EXCEPT operator to exclude specific subsets of data.\"\n",
    "\n",
    "\n",
    "# A comprehensive list of paths using the Enum members\n",
    "CHALLENGE_PATHS = [\n",
    "    {\n",
    "        \"id\": \"PATH_GEOGRAPHIC_WEALTH\",\n",
    "        \"title\": \"Regional Liquidity Analysis\",\n",
    "        \"tables\": [\"Country\", \"City\", \"Branch\", \"Account\"],\n",
    "        \"description\": \"Create a query to obtain the total number of account balances are distributed across specific jurisdictions.\",\n",
    "        \"valid_requirements\": [\n",
    "            SQLRequirement.JOIN,\n",
    "            SQLRequirement.AGGREGATION,\n",
    "            SQLRequirement.WINDOWING,\n",
    "            SQLRequirement.CTE,\n",
    "            SQLRequirement.ORDER,\n",
    "        ],\n",
    "        \"output_columns\": [\"country_name\", \"city_name\", \"total_balance\", \"wealth_rank\"],\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"PATH_GHOST_USERS\",\n",
    "        \"title\": \"Silent User Audit\",\n",
    "        \"tables\": [\"User\", \"Account\", \"AuditLog\"],\n",
    "        \"description\": \"Find users with significant funds who show no security activity in the logs.\",\n",
    "        \"valid_requirements\": [\n",
    "            SQLRequirement.EXCEPT_LOGIC,\n",
    "            SQLRequirement.JOIN,\n",
    "            SQLRequirement.TEMPORAL,\n",
    "        ],\n",
    "        \"output_columns\": [\"user_id\", \"username\"],\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"PATH_SECURITY_LOGS\",\n",
    "        \"title\": \"User Behavioral Forensics\",\n",
    "        \"tables\": [\"User\", \"AuditLog\"],\n",
    "        \"description\": \"Examine security event patterns and session frequency for users.\",\n",
    "        \"valid_requirements\": [\n",
    "            SQLRequirement.JOIN,\n",
    "            SQLRequirement.WINDOWING,\n",
    "            SQLRequirement.SUBQUERY,\n",
    "            SQLRequirement.LIMIT_OFFSET,\n",
    "            SQLRequirement.ORDER,\n",
    "        ],\n",
    "        \"output_columns\": [\"username\", \"ip_address\", \"event_type\", \"event_rank\"],\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"PATH_CASH_FLOW\",\n",
    "        \"title\": \"Consolidated Ledger Audit\",\n",
    "        \"tables\": [\"Account\", \"Deposit\", \"Withdraw\"],\n",
    "        \"description\": \"Compare inflows (deposits) and outflows (withdrawals) for specific accounts.\",\n",
    "        \"valid_requirements\": [\n",
    "            SQLRequirement.UNION,\n",
    "            SQLRequirement.INTERSECTION,\n",
    "            SQLRequirement.CTE,\n",
    "            SQLRequirement.AGGREGATION,\n",
    "            SQLRequirement.JOIN,\n",
    "        ],\n",
    "        \"output_columns\": [\n",
    "            \"account_number\",\n",
    "            \"movement_type\",\n",
    "            \"amount\",\n",
    "            \"transaction_date\",\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"PATH_TRANSFER_VELOCITY\",\n",
    "        \"title\": \"Currency Transfer Analysis\",\n",
    "        \"tables\": [\"Account\", \"Transaction\", \"Currency\"],\n",
    "        \"description\": \"Track the volume of 'Transfer' type transactions across different currency codes.\",\n",
    "        \"valid_requirements\": [\n",
    "            SQLRequirement.JOIN,\n",
    "            SQLRequirement.AGGREGATION,\n",
    "            SQLRequirement.WINDOWING,\n",
    "            SQLRequirement.CTE,\n",
    "            SQLRequirement.SUBQUERY,\n",
    "        ],\n",
    "        \"output_columns\": [\n",
    "            \"source_account\",\n",
    "            \"destiny_account\",\n",
    "            \"amount\",\n",
    "            \"currency_code\",\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"PATH_CARD_EXPOSURE\",\n",
    "        \"title\": \"Card Holder Risk Assessment\",\n",
    "        \"tables\": [\"User\", \"Account\", \"Card\"],\n",
    "        \"description\": \"Evaluate the financial backing of Credit vs Debit cards based on user balances.\",\n",
    "        \"valid_requirements\": [\n",
    "            SQLRequirement.JOIN,\n",
    "            SQLRequirement.SUBQUERY,\n",
    "            SQLRequirement.AGGREGATION,\n",
    "            SQLRequirement.ORDER,\n",
    "            SQLRequirement.LIMIT_OFFSET,\n",
    "        ],\n",
    "        \"output_columns\": [\"full_name\", \"card_number\", \"card_type\", \"balance\"],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3d24d24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- üìù UNIQUE SQL SPECIFICATION: STUDENT 101 ---\n",
      "\n",
      "MISSION: Currency Transfer Analysis\n",
      "DESCRIPTION: Track the volume of 'Transfer' type transactions across different currency codes.\n",
      "\n",
      "MISSION LOGIC:\n",
      "1. DATA SCOPE: Filter records exclusively for the period: June 2024.\n",
      "2. THRESHOLD: Only include records where (value) is > $4131.\n",
      "3. LOGIC GATES: Your query must satisfy the following:\n",
      "\n",
      "TECHNICAL REQUIREMENTS:\n",
      "   - [ ] Must include aggregation functions (SUM, AVG, COUNT, etc.).\n",
      "   - [ ] Must include partitioning and window functions (RANK, DENSE_RANK, ROW_NUMBER, etc.).\n",
      "   - [ ] Must utilize a subquery (correlated or non-correlated) in a WHERE or HAVING clause.\n",
      "\n",
      "STRICT OUTPUT SCHEMA (Order matters):\n",
      "source_account, destiny_account, amount, currency_code\n",
      "\n",
      "ORDERING:\n",
      "- Order by the final column in your schema DESC.\n",
      "- Return the top 6 results.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict, List\n",
    "\n",
    "\n",
    "class SQLExerciseGenerator:\n",
    "    def __init__(self, paths: List[Dict[str, Any]]):\n",
    "        self.paths = paths\n",
    "\n",
    "    def generate(self, student_id: int) -> str:\n",
    "        # 1. Deterministic Seeding\n",
    "        random.seed(student_id)\n",
    "        \n",
    "        # 2. Select Path and Metadata\n",
    "        path = random.choice(self.paths)\n",
    "        \n",
    "        # 3. Select 3 Requirements valid for this path\n",
    "        selected_reqs = random.sample(\n",
    "            path[\"valid_requirements\"], \n",
    "            k=min(3, len(path[\"valid_requirements\"]))\n",
    "        )\n",
    "        \n",
    "        # 4. Parameterized Values\n",
    "        # Relative date: Pick a year from the last 2 years relative to 'now'\n",
    "        now = datetime.now()\n",
    "        target_year = now.year - (student_id % 2) \n",
    "        target_month = (student_id % 12) + 1\n",
    "        month_name = datetime(2000, target_month, 1).strftime('%B')\n",
    "        \n",
    "        # Unique thresholds and limits\n",
    "        v_threshold = (student_id * 31) % 5000 + 1000\n",
    "        v_limit = (student_id % 5) + 5\n",
    "        \n",
    "        # 5. Format the Mission Description\n",
    "        # Injects anchor_metric and primary_entity into the template string\n",
    "        formatted_desc = path[\"description\"].format(\n",
    "            anchor_metric=path.get(\"anchor_metric\", \"value\"),\n",
    "            primary_entity=path.get(\"primary_entity\", \"record\")\n",
    "        )\n",
    "        \n",
    "        # 6. Build the Technical Requirements List\n",
    "        req_list_str = \"\\n\".join([f\"   - [ ] {req.value}\" for req in selected_reqs])\n",
    "\n",
    "        # 7. Final Prompt Assembly\n",
    "        prompt = f\"\"\"\n",
    "--- üìù UNIQUE SQL SPECIFICATION: STUDENT {student_id} ---\n",
    "\n",
    "MISSION: {path['title']}\n",
    "DESCRIPTION: {formatted_desc}\n",
    "\n",
    "MISSION LOGIC:\n",
    "1. DATA SCOPE: Filter records exclusively for the period: {month_name} {target_year}.\n",
    "2. THRESHOLD: Only include records where ({path.get('anchor_metric', 'value')}) is > ${v_threshold}.\n",
    "3. LOGIC GATES: Your query must satisfy the following:\n",
    "\n",
    "TECHNICAL REQUIREMENTS:\n",
    "{req_list_str}\n",
    "\n",
    "STRICT OUTPUT SCHEMA (Order matters):\n",
    "{\", \".join(path['output_columns'])}\n",
    "\n",
    "ORDERING:\n",
    "- Order by the final column in your schema DESC.\n",
    "- Return the top {v_limit} results.\n",
    "---\"\"\"\n",
    "        return prompt\n",
    "\n",
    "# --- Example Execution ---\n",
    "if __name__ == \"__main__\":    \n",
    "    generator = SQLExerciseGenerator(CHALLENGE_PATHS)\n",
    "    \n",
    "    # Generate for a specific student\n",
    "    print(generator.generate(student_id=101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f89cee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class SQLExerciseGenerator:\n",
    "    def __init__(self):\n",
    "        # Full library of technical requirements\n",
    "        self.requirements: Dict[str, str] = {\n",
    "            \"aggregation\": \"Must include aggregate functions (SUM, AVG, COUNT, etc.) with GROUP BY.\",\n",
    "            \"windowing\": \"Requires a Window Function (e.g., RANK, DENSE_RANK, ROW_NUMBER, etc.) to categorize data.\",\n",
    "            \"order\": \"Must be explicitly ordered by a calculated metric or alias.\",\n",
    "            \"limit_offset\": \"Must use LIMIT and OFFSET to return a specific slice of the results.\",\n",
    "            \"subquery\": \"Must utilize a subquery (correlated or non-correlated) in a WHERE or HAVING clause.\",\n",
    "            \"cte\": \"The query must be structured using at least one Common Table Expression (WITH clause).\",\n",
    "            \"join\": \"Requires a multi-stage join across at least three distinct tables.\",\n",
    "            \"union\": \"Requires the use of UNION to combine results from Deposits and Withdraws.\",\n",
    "            \"intersection\": \"Must use INTERSECT to find overlap between AuditLog and Account types.\",\n",
    "            \"temporal\": \"Must use SQL date functions (EXTRACT, DATE_PART, or TO_CHAR) for month/year filtering.\"\n",
    "        }\n",
    "\n",
    "        # Expanded paths covering all tables in your SQLModel schema\n",
    "        self.paths: List[Dict[str, Any]] = [\n",
    "            {\n",
    "                \"id\": \"GEO_WEALTH\",\n",
    "                \"title\": \"Geographic Liquidity Map\",\n",
    "                \"path\": \"Country ‚Üî City ‚Üî Branch ‚Üî Account\",\n",
    "                \"valid_reqs\": [\"join\", \"aggregation\", \"windowing\", \"cte\", \"temporal\"],\n",
    "                \"schema\": [\"country_name\", \"city_name\", \"total_balance\", \"wealth_rank\"]\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"USER_FORENSICS\",\n",
    "                \"title\": \"Security & Activity Audit\",\n",
    "                \"path\": \"User ‚Üî AuditLog ‚Üî Account\",\n",
    "                \"valid_reqs\": [\"windowing\", \"subquery\", \"temporal\", \"order\", \"join\"],\n",
    "                \"schema\": [\"username\", \"email\", \"event_type\", \"account_balance\", \"event_order\"]\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"CASH_FLOW\",\n",
    "                \"title\": \"Global Movement Ledger\",\n",
    "                \"path\": \"Account ‚Üî Deposit ‚Üî Withdraw\",\n",
    "                \"valid_reqs\": [\"union\", \"intersection\", \"cte\", \"temporal\", \"aggregation\"],\n",
    "                \"schema\": [\"account_number\", \"flow_type\", \"amount\", \"entry_date\"]\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"FX_TRANSFERS\",\n",
    "                \"title\": \"Currency Transfer Velocity\",\n",
    "                \"path\": \"Transaction ‚Üî Account ‚Üî Currency\",\n",
    "                \"valid_reqs\": [\"join\", \"aggregation\", \"windowing\", \"cte\", \"temporal\"],\n",
    "                \"schema\": [\"account_number\", \"currency_code\", \"total_transferred\", \"transfer_rank\"]\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"CARD_SECURITY\",\n",
    "                \"title\": \"Cardholder Risk Assessment\",\n",
    "                \"path\": \"User ‚Üî Account ‚Üî Card\",\n",
    "                \"valid_reqs\": [\"join\", \"subquery\", \"aggregation\", \"order\", \"limit_offset\"],\n",
    "                \"schema\": [\"full_name\", \"card_number\", \"card_type\", \"current_balance\"]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    def generate(self, student_id: int) -> str:\n",
    "        random.seed(student_id)\n",
    "        \n",
    "        # --- 1. DYNAMIC RELATIVE DATE LOGIC ---\n",
    "        now = datetime.now()\n",
    "        # Randomly pick a year from the last 2 years (relative to today)\n",
    "        target_year = now.year - (student_id % 2) \n",
    "        target_month = (student_id % 12) + 1\n",
    "        month_name = datetime(2000, target_month, 1).strftime('%B')\n",
    "        \n",
    "        # --- 2. PATH & REQUIREMENT SELECTION ---\n",
    "        path = random.choice(self.paths)\n",
    "        req_keys = random.sample(path[\"valid_reqs\"], k=min(3, len(path[\"valid_reqs\"])))\n",
    "        \n",
    "        # Force temporal requirement if the path relies on the date scope\n",
    "        if \"temporal\" in path[\"valid_reqs\"] and \"temporal\" not in req_keys:\n",
    "            req_keys[0] = \"temporal\"\n",
    "            \n",
    "        # --- 3. PARAMETERIZED VALUES ---\n",
    "        v_threshold = (student_id * 31) % 5000 + 1000\n",
    "        v_limit = (student_id % 5) + 5\n",
    "        \n",
    "        # --- 4. ASSEMBLY ---\n",
    "        requirements_formatted = \"\\n\".join([f\"   - [ ] {self.requirements[rk]}\" for rk in req_keys])\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "--- üìù UNIQUE SQL SPECIFICATION: STUDENT {student_id} ---\n",
    "\n",
    "MISSION: {path['title']}\n",
    "STRUCTURE: {path['path']}\n",
    "\n",
    "MISSION LOGIC:\n",
    "1. DATA SCOPE: Filter records exclusively for the period: {month_name} {target_year}.\n",
    "2. THRESHOLD: Only include records where the primary metric (balance/amount) is > ${v_threshold}.\n",
    "3. LOGIC GATES: Your query must satisfy the following:\n",
    "\n",
    "TECHNICAL REQUIREMENTS:\n",
    "{requirements_formatted}\n",
    "\n",
    "STRICT OUTPUT SCHEMA (Order matters):\n",
    "{\", \".join(path['schema'])}\n",
    "\n",
    "ORDERING:\n",
    "- Order by the final column in your schema DESC.\n",
    "- Return the top {v_limit} results.\n",
    "---\"\"\"\n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b357f036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- üìù UNIQUE SQL SPECIFICATION: STUDENT 101 ---\n",
      "\n",
      "MISSION: Cardholder Risk Assessment\n",
      "STRUCTURE: User ‚Üî Account ‚Üî Card\n",
      "\n",
      "MISSION LOGIC:\n",
      "1. DATA SCOPE: Filter records exclusively for the period: June 2024.\n",
      "2. THRESHOLD: Only include records where the primary metric (balance/amount) is > $4131.\n",
      "3. LOGIC GATES: Your query must satisfy the following:\n",
      "\n",
      "TECHNICAL REQUIREMENTS:\n",
      "   - [ ] Must utilize a subquery (correlated or non-correlated) in a WHERE or HAVING clause.\n",
      "   - [ ] Must include aggregate functions (SUM, AVG, or COUNT) with GROUP BY.\n",
      "   - [ ] Must use LIMIT and OFFSET to return a specific slice of the results.\n",
      "\n",
      "STRICT OUTPUT SCHEMA (Order matters):\n",
      "full_name, card_number, card_type, current_balance\n",
      "\n",
      "ORDERING:\n",
      "- Order by the final column in your schema DESC.\n",
      "- Return the top 6 results.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# --- TEST ---\n",
    "generator = SQLExerciseGenerator()\n",
    "print(generator.generate(student_id=101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad2d771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6ba9ad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hardened_challenge(student_id):\n",
    "    random.seed(student_id)\n",
    "    \n",
    "    # MISSION: Calculate a 'Control Sum'\n",
    "    # The student MUST find these specific values in their DB to get it right.\n",
    "    parts = [\n",
    "        \"the count of characters in the user's city name\",\n",
    "        \"the number of 'LOGIN' events they have\",\n",
    "        \"the first digit of their oldest account number\"\n",
    "    ]\n",
    "    selected_parts = random.sample(parts, 2)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    --- üõ°Ô∏è HARDENED SQL CHALLENGE: STUDENT {student_id} ---\n",
    "    \n",
    "    GOAL: Generate a High-Value User Report.\n",
    "    \n",
    "    LOGIC: \n",
    "    1. Select users with a balance > $5000.\n",
    "    2. Join with City and AuditLog tables.\n",
    "    \n",
    "    MANDATORY VERIFICATION COLUMN:\n",
    "    You must include a column named 'VERIFICATION_KEY'. \n",
    "    It must be calculated as: ({selected_parts[0]}) + ({selected_parts[1]}).\n",
    "    \n",
    "    OUTPUT SCHEMA:\n",
    "    username, total_balance, city_name, VERIFICATION_KEY\n",
    "    \n",
    "    ORDER BY: VERIFICATION_KEY DESC\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c027bae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    --- üõ°Ô∏è HARDENED SQL CHALLENGE: STUDENT 100 ---\n",
      "\n",
      "    GOAL: Generate a High-Value User Report.\n",
      "\n",
      "    LOGIC: \n",
      "    1. Select users with a balance > $5000.\n",
      "    2. Join with City and AuditLog tables.\n",
      "\n",
      "    MANDATORY VERIFICATION COLUMN:\n",
      "    You must include a column named 'VERIFICATION_KEY'. \n",
      "    It must be calculated as: (the count of characters in the user's city name) + (the number of 'LOGIN' events they have).\n",
      "\n",
      "    OUTPUT SCHEMA:\n",
      "    username, total_balance, city_name, VERIFICATION_KEY\n",
      "\n",
      "    ORDER BY: VERIFICATION_KEY DESC\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(generate_hardened_challenge(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "652aec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def create_random_challenge(student_id):\n",
    "    random.seed(student_id)\n",
    "    \n",
    "    # 1. Choose a \"Focal Point\" (The core entity we are investigating)\n",
    "    focal_points = [\"User\", \"Account\", \"Branch\", \"City\", \"Currency\"]\n",
    "    focus = random.choice(focal_points)\n",
    "    \n",
    "    # 2. Choose a \"Relationship Depth\" (How many joins)\n",
    "    depth = random.randint(2, 4)\n",
    "    \n",
    "    # 3. Choose a \"Technical Complexity\" (The SQL trick)\n",
    "    complexities = [\n",
    "        {\"name\": \"Set Difference\", \"logic\": \"NOT EXISTS\", \"hint\": \"Find X that have no Y\"},\n",
    "        {\"name\": \"Window Ranking\", \"logic\": \"DENSE_RANK()\", \"hint\": \"Rank X by Y within Z\"},\n",
    "        {\"name\": \"Temporal Gap\", \"logic\": \"INTERVAL\", \"hint\": \"Find X then Y within N minutes\"},\n",
    "        {\"name\": \"Aggregated Comparison\", \"logic\": \"HAVING\", \"hint\": \"Find X where total Y > average Z\"}\n",
    "    ]\n",
    "    comp = random.choice(complexities)\n",
    "    \n",
    "    # 4. Define the Output Schema (Strictly ordered)\n",
    "    # We randomize the required columns to make the queries unique\n",
    "    possible_cols = [\"id\", \"name\", \"balance\", \"count\", \"rank\", \"timestamp\"]\n",
    "    selected_cols = random.sample(possible_cols, 3) + [\"calculated_metric\"]\n",
    "    \n",
    "    # 5. Build the Prompt\n",
    "    prompt = f\"\"\"\n",
    "    --- üèÜ CUSTOM CHALLENGE FOR STUDENT {student_id} ---\n",
    "    FOCUS: {focus}-centric analysis.\n",
    "    COMPLEXITY: {comp['name']} ({comp['hint']}).\n",
    "    \n",
    "    MISSION: Identify {focus} entities where... [Logic generated based on {comp['logic']}]\n",
    "    \n",
    "    REQUIRED OUTPUT COLUMNS (Exact order):\n",
    "    {\", \".join([f\"'{c}'\" for c in selected_cols])}\n",
    "    \n",
    "    ORDERING: {random.choice(selected_cols)} {'DESC' if random.random() > 0.5 else 'ASC'}\n",
    "    \"\"\"\n",
    "    \n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"inject_type\": comp['name'],\n",
    "        \"expected_columns\": selected_cols,\n",
    "        \"seed\": student_id\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "aae19f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_anti_copy_challenge(student_id):\n",
    "    random.seed(student_id)\n",
    "    \n",
    "    # 1. TOPOLOGY: How the tables must connect\n",
    "    topologies = [\n",
    "        {\"desc\": \"Star Join\", \"hint\": \"Join User as the center to Branch and AuditLog separately.\"},\n",
    "        {\"desc\": \"Linear Chain\", \"hint\": \"Connect Country ‚Üí City ‚Üí Branch ‚Üí Account in a single chain.\"},\n",
    "        {\"desc\": \"Self-Referential\", \"hint\": \"You must join the Transaction table to itself.\"}\n",
    "    ]\n",
    "    \n",
    "    # 2. STRUCTURAL CONSTRAINT: The mandatory SQL feature\n",
    "    constraints = [\n",
    "        {\"type\": \"CTE\", \"req\": \"Must define the logic inside a WITH clause.\"},\n",
    "        {\"type\": \"Subquery\", \"req\": \"The main filter must reside in a WHERE (SELECT...) subquery.\"},\n",
    "        {\"type\": \"Window\", \"req\": \"You must use a Window Function (OVER PARTITION BY).\"},\n",
    "        {\"type\": \"Set Op\", \"req\": \"You must use EXCEPT or INTERSECT to find the result.\"}\n",
    "    ]\n",
    "    \n",
    "    # 3. ALIASING RULES: (Prevents copy-pasting code directly)\n",
    "    alias_styles = [\n",
    "        \"Use 'u_info' for User and 'acc_data' for Account.\",\n",
    "        \"Prefix all column aliases with 'out_'.\",\n",
    "        \"Use Spanish aliases (e.g., 'saldo_total', 'nombre_usuario').\",\n",
    "        \"Use underscore-separated uppercase (e.g., USER_NAME_KEY).\"\n",
    "    ]\n",
    "\n",
    "    topology = random.choice(topologies)\n",
    "    constraint = random.choice(constraints)\n",
    "    alias = random.choice(alias_styles)\n",
    "    \n",
    "    # Randomly select 4 columns from the available schema\n",
    "    all_columns = [\"u.username\", \"u.email\", \"a.balance\", \"a.account_number\", \"c.name as country\", \"cur.code\"]\n",
    "    output_columns = random.sample(all_columns, 4)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    --- üìù UNIQUE SQL SPECIFICATION: STUDENT {student_id} ---\n",
    "    \n",
    "    STRUCTURE: {topology['desc']}\n",
    "    MANDATORY TECHNIQUE: {constraint['type']} ({constraint['req']})\n",
    "    NAMING CONVENTION: {alias}\n",
    "    \n",
    "    MISSION: \n",
    "    [Insert Random Logic Here: e.g., Find users with a balance > city average]\n",
    "    \n",
    "    STRICT OUTPUT SCHEMA (Order matters):\n",
    "    {', '.join(output_columns)}\n",
    "    \n",
    "    ORDERING: \n",
    "    Order by the 3rd column in your SELECT list {random.choice(['ASC', 'DESC'])}.\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e6ae0f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    --- üìù UNIQUE SQL SPECIFICATION: STUDENT 100 ---\n",
      "\n",
      "    STRUCTURE: Star Join\n",
      "    MANDATORY TECHNIQUE: Set Op (You must use EXCEPT or INTERSECT to find the result.)\n",
      "    NAMING CONVENTION: Use underscore-separated uppercase (e.g., USER_NAME_KEY).\n",
      "\n",
      "    MISSION: \n",
      "    [Insert Random Logic Here: e.g., Find users with a balance > city average]\n",
      "\n",
      "    STRICT OUTPUT SCHEMA (Order matters):\n",
      "    u.email, a.account_number, a.balance, cur.code\n",
      "\n",
      "    ORDERING: \n",
      "    Order by the 3rd column in your SELECT list ASC.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(generate_anti_copy_challenge(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bb184c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_student_data(session, challenge):\n",
    "    \"\"\"\n",
    "    This function reads the 'inject_type' and 'seed' from the challenge\n",
    "    and forces the DB to have 3-5 rows that match the criteria.\n",
    "    \"\"\"\n",
    "    random.seed(challenge['seed']) # Use same seed to match the problem\n",
    "    \n",
    "    if challenge['inject_type'] == \"Temporal Gap\":\n",
    "        # Force 5 users to have the 'rapid update' timestamps\n",
    "        for _ in range(5):\n",
    "            u = session.exec(select(User)).random_one()\n",
    "            t1 = datetime.now()\n",
    "            t2 = t1 + timedelta(minutes=random.randint(1, 4))\n",
    "            # ... insert logs ...\n",
    "            \n",
    "    elif challenge['inject_type'] == \"Set Difference\":\n",
    "        # Force 5 branches to have ZERO accounts despite being in active cities\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a7ac3c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_complex_exercise(student_id):\n",
    "    random.seed(student_id)\n",
    "    \n",
    "    # 1. EXPANDED ARCHITECTURAL PATHS (The \"From\" clause)\n",
    "    paths = [\n",
    "        \"User ‚Üî Account ‚Üî Transaction (Flow analysis)\",\n",
    "        \"User ‚Üî AuditLog (Behavioral analysis)\",\n",
    "        \"Branch ‚Üî City ‚Üî Country (Geographic analysis)\",\n",
    "        \"Account ‚Üî Card (Product usage)\",\n",
    "        \"User ‚Üî Account ‚Üî Currency ‚Üî Country (Cross-border analysis)\",\n",
    "        \"Account ‚Üî Deposit ‚Üî Withdraw (Liquidity analysis)\",\n",
    "        \"City ‚Üî Branch ‚Üî Account ‚Üî Transaction (Local economic activity)\",\n",
    "        \"User ‚Üî AuditLog (Security/Forensics)\",\n",
    "        \"Currency ‚Üî Account ‚Üî User (Foreign Exchange Exposure)\",\n",
    "        \"Country ‚Üî City ‚Üî User ‚Üî Account (Demographic wealth)\",\n",
    "        \"Card ‚Üî Account ‚Üî Deposit (Credit-limit/Prepaid behavior)\",\n",
    "        \"User ‚Üî Transaction (Peer-to-peer / Direct flow)\",\n",
    "        \"Branch ‚Üî Account (Operational load)\",\n",
    "        \"AuditLog (Self-Join for Session analysis)\",\n",
    "        \"Currency ‚Üî Country (National monetary metrics)\"\n",
    "    ]\n",
    "    \n",
    "    # 2. EXPANDED STRUCTURAL REQUIREMENTS (The \"How\")\n",
    "    structures = [\n",
    "        {\"desc\": \"Relative Comparison\", \"sql_hint\": \"Requires a Correlated Subquery or a JOIN on a CTE/Subquery.\"},\n",
    "        {\"desc\": \"Threshold Frequency\", \"sql_hint\": \"Requires GROUP BY with a HAVING clause.\"},\n",
    "        {\"desc\": \"Non-Existence / Exclusion\", \"sql_hint\": \"Requires a LEFT JOIN with a NULL check or a NOT EXISTS/NOT IN clause.\"},\n",
    "        {\"desc\": \"Ranking/Positioning\", \"sql_hint\": \"Requires Window Functions (RANK(), DENSE_RANK(), or ROW_NUMBER()).\"},\n",
    "        {\"desc\": \"Temporal Gap / Sequence\", \"sql_hint\": \"Requires LEAD() or LAG() window functions, or a Self-Join on timestamps.\"},\n",
    "        {\"desc\": \"Set Theory Difference\", \"sql_hint\": \"Requires using EXCEPT or a combination of INTERSECT and subqueries.\"},\n",
    "        {\"desc\": \"Conditional Aggregation\", \"sql_hint\": \"Requires using CASE WHEN inside a SUM() or COUNT() function.\"},\n",
    "        {\"desc\": \"Running Totals / Cumulative\", \"sql_hint\": \"Requires a Window Function with an 'ORDER BY' in the OVER clause.\"}\n",
    "    ]\n",
    "    \n",
    "    # 3. EXPANDED DYNAMIC LOGIC POOL\n",
    "    logic_pool = [\n",
    "        \"Find users whose average transaction amount is higher than the average for their entire branch.\",\n",
    "        \"Identify the city where the currency exchange diversity (number of unique currencies) is highest.\",\n",
    "        \"Find users who have a 'LOGIN' audit log but have 0 associated accounts.\",\n",
    "        \"List accounts that have more withdrawals than deposits in terms of volume (sum), but fewer in terms of count.\",\n",
    "        \"Identify users who updated their 'EMAIL' and then added a 'CARD' within the same 24-hour period.\",\n",
    "        \"Find the 'Whale' users: those whose balance is in the top 5% of their specific country.\",\n",
    "        \"Find 'Dormant Accounts': users who haven't had a transaction in the last 6 months but have a balance > $val_b.\",\n",
    "        \"Identify IPs in the AuditLog that have successfully logged into more than {val_a} different accounts.\",\n",
    "        \"Find the branch that has the highest ratio of 'Debit' to 'Credit' cards issued.\",\n",
    "        \"Identify users who have accounts in more than {val_a} different currencies.\",\n",
    "        \"Calculate the month-over-month growth of total deposits for the year 2025.\",\n",
    "        \"Find users who have updated their LAST_NAME and FIRST_NAME in the same session (within 5 minutes).\",\n",
    "        \"Identify countries where the average account balance is below the global average.\",\n",
    "        \"Find users who have a 'Withdraw' larger than {val_a}% of their current total balance.\",\n",
    "        \"List the top 3 cities in each country by the number of 'Checking' accounts.\",\n",
    "        \"Detect 'Round-Trip' transactions: deposits followed by a withdraw of the exact same amount within 1 hour.\"\n",
    "    ]\n",
    "\n",
    "    selected_path = random.choice(paths)\n",
    "    selected_struct = random.choice(structures)\n",
    "    selected_logic = random.choice(logic_pool)\n",
    "    \n",
    "    # Random parameters for uniqueness\n",
    "    val_a = random.choice([2, 5, 10, 15, 25])\n",
    "    val_b = random.choice([500, 1000, 5000, 10000, 25000])\n",
    "\n",
    "    # Final logic formatting\n",
    "    mission = selected_logic.replace('{val_a}', str(val_a)).replace('{val_b}', str(val_b))\n",
    "    mission = mission.replace('5%', f'{val_a}%').replace('24-hour', f'{val_a}-hour')\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    --- üèÜ ADVANCED CHALLENGE FOR STUDENT {student_id} ---\n",
    "    \n",
    "    CONTEXTUAL PATH: {selected_path}\n",
    "    TECHNICAL FOCUS: {selected_struct['desc']}\n",
    "    \n",
    "    MISSION:\n",
    "    {mission}\n",
    "    \n",
    "    SPECIFIC CONSTRAINTS:\n",
    "    - Use a minimum threshold of ${val_b} where applicable.\n",
    "    - {selected_struct['sql_hint']}\n",
    "    - Output must be scannable: use clear column aliases (e.g., 'total_volume', 'user_ranking').\n",
    "    - Only consider data updated/created in the year 2025.\n",
    "    - Result must be ordered by {random.choice(['the primary metric desc', 'username asc', 'timestamp desc'])}.\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "24ac5e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    --- üèÜ ADVANCED CHALLENGE FOR STUDENT 101 ---\n",
      "\n",
      "    CONTEXTUAL PATH: Country ‚Üî City ‚Üî User ‚Üî Account (Demographic wealth)\n",
      "    TECHNICAL FOCUS: Ranking/Positioning\n",
      "\n",
      "    MISSION:\n",
      "    Find users who have updated their LAST_NAME and FIRST_NAME in the same session (within 5 minutes).\n",
      "\n",
      "    SPECIFIC CONSTRAINTS:\n",
      "    - Use a minimum threshold of $500 where applicable.\n",
      "    - Requires Window Functions (RANK(), DENSE_RANK(), or ROW_NUMBER()).\n",
      "    - Output must be scannable: use clear column aliases (e.g., 'total_volume', 'user_ranking').\n",
      "    - Only consider data updated/created in the year 2025.\n",
      "    - Result must be ordered by timestamp desc.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(generate_complex_exercise(101))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relational-databases",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
